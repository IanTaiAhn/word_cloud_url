# Shared helpers (e.g. caching, batching)
# kind of just notes in here now

# import re
# import nltk
# import os
# from nltk.corpus import stopwords
# from nltk.tokenize import word_tokenize
# from nltk.stem import WordNetLemmatizer
# from textblob import TextBlob
# import pandas as pd
# import numpy as np
# from sklearn.feature_extraction.text import TfidfVectorizer
# from gensim.models import KeyedVectors
# from sentence_transformers import SentenceTransformer
# from sklearn.cluster import KMeans
# from sklearn.decomposition import LatentDirichletAllocation
# from sklearn.decomposition import NMF
# from sklearn.cluster import DBSCAN
# from sklearn.metrics.pairwise import cosine_distances
# from sklearn.mixture import GaussianMixture
# from wordcloud import WordCloud
# import seaborn as sns
# from sklearn.metrics.pairwise import cosine_similarity
# import matplotlib.pyplot as plt
# from matplotlib.colors import ListedColormap
#chat gpt generated...
# from transformers import AutoModel, AutoTokenizer

# model_name = "roberta-base"  # or better: "distilroberta-base"
# tokenizer = AutoTokenizer.from_pretrained(model_name)
# model = AutoModel.from_pretrained(model_name)

####NLTK or Spacy####
# Receives text and cleans/filters it

####WORD TO NUMBER VECTOR FOR ML PROCESSING####
# Uses cleaned text to group the data?

####WORD CLOUD####